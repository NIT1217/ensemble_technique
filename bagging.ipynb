{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# THEORETICAL QUESTION"
      ],
      "metadata": {
        "id": "A46x4s5RbAEy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 1.Can we use Bagging for regression problems?\n",
        " - yes , bagging can be used for the regression and classification both"
      ],
      "metadata": {
        "id": "CsT88oyWNbpY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 2.What is the difference between multiple model training and single model training?\n",
        "\n",
        " - single model training is the training of a model at a time , it is easy to interprete and it is faster as compare to multi model training and sometime it can causes ooverfitting and underfitting , which decrease its accurecy\n",
        "\n",
        " - multi model training is traing of many models at a time , it is also called ensambles, it is slower and more accurate and decrease the chance of overfitting and underfitting, hence model is more accurate"
      ],
      "metadata": {
        "id": "cKb7Qfv6NFIM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Explain the concept of feature randomness in Random Forest\n",
        "- As random forest is part of bagging is the training data used here are choosed randomly and with replecemnt, which implies the concept of randomness in randomForest\n"
      ],
      "metadata": {
        "id": "cFvOv1HqNFFX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.What is OOB (Out-of-Bag) Score?\n",
        "- the part of training data which are not used in model training in bagging process are are called OOB and sum of OOB of all the base models causes the OOB score\n"
      ],
      "metadata": {
        "id": "tEEzT9thNFC0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 5.How can you measure the importance of features in a Random Forest model?\n",
        "\n",
        "- we use Mean Decrease in Impurity (Gini Importance), to measure the important feature by the attribute called\n",
        "importances = model.feature_importances_"
      ],
      "metadata": {
        "id": "QoxAosTdNFAH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 6.Explain the working principle of a Bagging Classifier?\n",
        "\n",
        " -in bagging classifier the train train data is splited can cause the formation of base moddel and  base models are used  to give predicted model and , all the predicted models are used to give a final prdicted model based on votingClassifier\n"
      ],
      "metadata": {
        "id": "gFnK9FwyNE9D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.How do you evaluate a Bagging Classifier’s performance?\n",
        "it can be evaluated by caonfusion matrics, accurecy score,classification report\n"
      ],
      "metadata": {
        "id": "DPCOe0mHNE6V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.How does a Bagging Regressor work?\n",
        "\n",
        "\n",
        "- in bagging regressor the  train data is splited can cause the formation of base moddel and  base models are used  to give predicted model and , all the predicted models are used to give a final prdicted model based on votingRegressor(average)\n",
        "\n"
      ],
      "metadata": {
        "id": "1WPR8N5MNE3t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.What is the main advantage of ensemble techniques?\n",
        "- ensemble techniques cause the formation of final model based on many base model which increase the efficency and accurecy of the final model\n"
      ],
      "metadata": {
        "id": "pkNh5zBTNE0V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 10.What is the main challenge of ensemble method?\n",
        " - slower model building process,\n",
        " - use multi model training concept , so its more complex and costly\n",
        " - hard to deploy\n"
      ],
      "metadata": {
        "id": "EJCfFiChNEsR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 11. Explain the key idea behind ensemble techniques?\n",
        " - ensembles techniques works on the concept of making a final model based on multi model  training which can be of either same algorithum and can be of diffrent algorithum\n"
      ],
      "metadata": {
        "id": "lPZ4J6DIVxUd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 1. What is a Random Forest Classifier?\n",
        " - random forest classifier is one of the bagging technique , which use base models of same algorithum. and it causes the reduction in overfitting\n"
      ],
      "metadata": {
        "id": "sG7XT6mIVx_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13.What are the main types of ensemble techniques?\n",
        "1. Bagging\n",
        "2. boosting\n",
        "3. stacking\n"
      ],
      "metadata": {
        "id": "KgyBKZ0qVyVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 14.What is ensemble learning in machine learning?\n",
        " - Ensemble learning is a technique where multiple models (called base learners or weak learners) are trained and combined to solve the same problem — with the goal of achieving better performance than any single model alone.\n",
        "\n"
      ],
      "metadata": {
        "id": "G94rhkagVyw3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. When should we avoid using ensemble methods?\n",
        "- for small datasets\n",
        "- when computing power and time is limited\n",
        "- diversity between the base learners and weak learners are less\n",
        "\n"
      ],
      "metadata": {
        "id": "FXDlqtEqVzM2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. How does Bagging help in reducing overfitting?\n",
        "- Overfitting happens when a model learns the noise in the data. Bagging reduces this by averaging multiple noisy models, smoothing out the errors.\n"
      ],
      "metadata": {
        "id": "CMc9ylYyVzi1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 17.Why is Random Forest better than a single Decision Tree?\n",
        " - random forest works on the principle of multi- model traing which cause the model to be more accurate and less noisy, which makes it better the Single decision tree\n"
      ],
      "metadata": {
        "id": "ggt-tb6YVz2M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 17. What is the role of bootstrap sampling in Bagging?\n",
        " - Bootstrap sampling is the foundation of Bagging (Bootstrap Aggregating). It ensures that each base model in the ensemble sees a slightly different version of the training data — which is crucial for diversity and variance reduction.\n",
        "\n"
      ],
      "metadata": {
        "id": "0AzvbekfV0pY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 19.What are some real-world applications of ensemble techniques?\n",
        " - Ensemble methods like Bagging, Boosting, and Stacking are used across industries because they improve prediction accuracy, reduce overfitting, and handle complex data well.\n",
        "\n",
        "Here are some real-world applications:\n",
        "medical use,Finance & Credit Risk Scoring, E-commerce & Recommendation Systems, Voice & Image Recognition, Weather Forecasting\n",
        "\n"
      ],
      "metadata": {
        "id": "T6dqLqBRV05W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20.  What is the difference between Bagging and Boosting?\n",
        "-  Bagging (Bootstrap Aggregating)\n",
        "Goal: Reduce variance, handle overfitting\n",
        "Data Sampling: Bootstrap samples (with replacement)\n",
        "Model Focus: All models treated equally\n",
        "Popular Algorithm: Random Forest\n",
        "\n",
        "\n",
        "Boosting\n",
        "Goal: Reduce bias, improve weak learners\n",
        "Data Sampling: Full dataset, weights updated after each round\n",
        "Model Focus: New models focus on errors of previous ones\n",
        "Combining: Weighted sum of model outputs\n",
        "Use Case: Complex tasks needing high accuracy"
      ],
      "metadata": {
        "id": "K_wiwhgvV1iI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PRACTICLE QUESTIONS"
      ],
      "metadata": {
        "id": "6pNQaybya2fw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#21.  Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "x,y = make_classification(n_samples= 1000, n_classes=2,n_informative=4,n_redundant=4, random_state=42 )\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,x_test,y_train,y_test= train_test_split(x,y, test_size = 0.2, random_state=42)\n",
        "x_train.shape,x_test.shape,y_train.shape,y_test.shape\n",
        "\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "bagging_clf = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(),\n",
        "    n_estimators=50,\n",
        "    random_state=42)\n",
        "\n",
        "bagging_clf.fit(x_train,y_train)\n",
        "y_pred=bagging_clf.predict(x_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report\n",
        "\n",
        "print(confusion_matrix(y_pred,y_test))\n",
        "print(accuracy_score(y_pred,y_test))\n",
        "print(classification_report(y_pred,y_test))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8_c7WZztayBm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd14615c-e45d-4fd2-ed52-81956de458ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[82 14]\n",
            " [ 8 96]]\n",
            "0.89\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.85      0.88        96\n",
            "           1       0.87      0.92      0.90       104\n",
            "\n",
            "    accuracy                           0.89       200\n",
            "   macro avg       0.89      0.89      0.89       200\n",
            "weighted avg       0.89      0.89      0.89       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#22.  Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "x,y = make_classification(n_samples= 1000,n_informative=4,n_redundant=4, random_state=42 )\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,x_test,y_train,y_test= train_test_split(x,y, test_size = 0.2, random_state=42)\n",
        "x_train.shape,x_test.shape,y_train.shape,y_test.shape\n",
        "\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "bagging_reg = BaggingRegressor(\n",
        "    estimator=DecisionTreeRegressor(),\n",
        "    n_estimators=50,\n",
        "    random_state=42)\n",
        "bagging_reg.fit(x_train,y_train)\n",
        "y_pred=bagging_reg.predict(x_test)\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "mean_squared_error(y_test,y_pred)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwUqf6vvV4uU",
        "outputId": "31c9bef5-47d8-41b1-cfcf-cc978dff894d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08056200000000001"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#23.  Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "data= load_breast_cancer()\n",
        "data1= data.data\n",
        "target= data.target\n",
        "df = pd.DataFrame(data1, columns= data.feature_names)\n",
        "\n",
        "\n",
        "df[\"target\"]=data.target\n",
        "\n",
        "x= df.iloc[:,:-1]\n",
        "y=df[\"target\"]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,x_test,y_train,y_test= train_test_split(x,y, test_size = 0.2, random_state=42)\n",
        "x_train.shape,x_test.shape,y_train.shape,y_test.shape\n",
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "param_grid ={'n_estimators':[20,30,40,100],\n",
        "             'criterion':[\"gini\",\"entropy\"],\n",
        "             'max_depth':[2,3,4,5]\n",
        "             }\n",
        "\n",
        "clf= GridSearchCV(estimator=rf,param_grid=param_grid,verbose = 2, cv=5,n_jobs=3)\n",
        "clf.fit(x_train,y_train)\n",
        "best_model= clf.best_estimator_\n",
        "y_pred_tuned=best_model.predict(x_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report\n",
        "\n",
        "print(confusion_matrix(y_pred_tuned,y_test))\n",
        "print(accuracy_score(y_pred_tuned,y_test))\n",
        "print(classification_report(y_pred_tuned,y_test))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqlRJHIIV4rc",
        "outputId": "cc7b56bc-f432-4ae4-b6b8-436a21711799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
            "[[40  1]\n",
            " [ 3 70]]\n",
            "0.9649122807017544\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.98      0.95        41\n",
            "           1       0.99      0.96      0.97        73\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.97      0.96       114\n",
            "weighted avg       0.97      0.96      0.97       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#24.  Train a Random Forest Regressor and compare its performance with a single Decision Tree\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "data= load_breast_cancer()\n",
        "data1= data.data\n",
        "target= data.target\n",
        "df = pd.DataFrame(data1, columns= data.feature_names)\n",
        "\n",
        "\n",
        "df[\"target\"]=data.target\n",
        "\n",
        "x= df.iloc[:,:-1]\n",
        "y=df[\"target\"]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,x_test,y_train,y_test= train_test_split(x,y, test_size = 0.2, random_state=42)\n",
        "x_train.shape,x_test.shape,y_train.shape,y_test.shape\n",
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "param_grid ={'n_estimators':[20,30,40,100],\n",
        "             'criterion':[\"gini\",\"entropy\"],\n",
        "             'max_depth':[2,3,4,5]\n",
        "             }\n",
        "\n",
        "clf= GridSearchCV(estimator=rf,param_grid=param_grid,verbose = 2, cv=5,n_jobs=3)\n",
        "clf.fit(x_train,y_train)\n",
        "best_model= clf.best_estimator_\n",
        "y_pred_tuned=best_model.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import r2_score,mean_squared_error\n",
        "\n",
        "print(r2_score(y_pred_tuned,y_test))\n",
        "\n",
        "\n",
        "# by single Decision tree\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "reg= DecisionTreeRegressor(max_depth=3,max_leaf_nodes=5,splitter=\"random\",criterion=\"squared_error\")\n",
        "reg.fit(x_train,y_train)\n",
        "\n",
        "y_pred=reg.predict(x_test)\n",
        "from sklearn.metrics import r2_score,mean_squared_error\n",
        "\n",
        "print(r2_score(y_pred,y_test))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sevCbueuV4ps",
        "outputId": "c48bebe0-386a-493b-87bb-5a87102eda7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
            "0.8476445038422986\n",
            "0.7824146913529441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#25.  Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "rf_clf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    oob_score=True,      # Enable OOB scoring\n",
        "    bootstrap=True,      # Required for OOB (enabled by default)\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "print(f\"OOB Score: {rf_clf.oob_score_}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gLdUOJrV4m0",
        "outputId": "96f887d0-4124-4526-dd33-e02c7adffa79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOB Score: 0.9547738693467337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Train a Bagging Classifier using SVM as a base estimator and print accuracy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "x,y = make_classification(n_samples= 1000, n_classes=2,n_informative=4,n_redundant=4, random_state=42 )\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,x_test,y_train,y_test= train_test_split(x,y, test_size = 0.2, random_state=42)\n",
        "x_train.shape,x_test.shape,y_train.shape,y_test.shape\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "bagging_clf = BaggingClassifier(\n",
        "    estimator=SVC(),\n",
        "    n_estimators=50,\n",
        "    random_state=42)\n",
        "\n",
        "bagging_clf.fit(x_train,y_train)\n",
        "y_pred=bagging_clf.predict(x_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report\n",
        "\n",
        "print(confusion_matrix(y_pred,y_test))\n",
        "print(accuracy_score(y_pred,y_test))\n",
        "print(classification_report(y_pred,y_test))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-J_GQDpGV4kW",
        "outputId": "53c0eb18-9b74-4be9-ec12-c8fd4876e864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[83 19]\n",
            " [ 7 91]]\n",
            "0.87\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.81      0.86       102\n",
            "           1       0.83      0.93      0.88        98\n",
            "\n",
            "    accuracy                           0.87       200\n",
            "   macro avg       0.87      0.87      0.87       200\n",
            "weighted avg       0.88      0.87      0.87       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#27.  Train a Random Forest Classifier with different numbers of trees and compare accuracy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "data= load_breast_cancer()\n",
        "data1= data.data\n",
        "target= data.target\n",
        "df = pd.DataFrame(data1, columns= data.feature_names)\n",
        "\n",
        "\n",
        "df[\"target\"]=data.target\n",
        "\n",
        "x= df.iloc[:,:-1]\n",
        "y=df[\"target\"]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,x_test,y_train,y_test= train_test_split(x,y, test_size = 0.2, random_state=42)\n",
        "x_train.shape,x_test.shape,y_train.shape,y_test.shape\n",
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report\n",
        "trees_count = [5,10,15,20]\n",
        "\n",
        "\n",
        "for n in trees_count:\n",
        "  rf = RandomForestClassifier(n_estimators=n, random_state=42)\n",
        "  rf.fit(x_train,y_train)\n",
        "  y_pred=rf.predict(x_test)\n",
        "  print(f\"accuracy score of {n} is{accuracy_score(y_pred,y_test)}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRleB2sFV4hv",
        "outputId": "44acea9c-74dd-42e9-9556-6495696da4aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy score of 5 is0.9473684210526315\n",
            "accuracy score of 10 is0.956140350877193\n",
            "accuracy score of 15 is0.9649122807017544\n",
            "accuracy score of 20 is0.9649122807017544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#28.  Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "x,y = make_classification(n_samples= 1000, n_classes=2,n_informative=4,n_redundant=4, random_state=42 )\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,x_test,y_train,y_test= train_test_split(x,y, test_size = 0.2, random_state=42)\n",
        "x_train.shape,x_test.shape,y_train.shape,y_test.shape\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "bagging_clf = BaggingClassifier(\n",
        "    estimator=LogisticRegression(),\n",
        "    n_estimators=50,\n",
        "    random_state=42)\n",
        "\n",
        "bagging_clf.fit(x_train,y_train)\n",
        "y_pred=bagging_clf.predict(x_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "print(roc_auc_score(y_pred,y_test))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4P4OcCq-rxIV",
        "outputId": "514f532c-8c7f-4ed8-8b0b-f3ca6481e670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6655165516551655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#29.  Train a Random Forest Regressor and analyze feature importance scores\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "data= load_breast_cancer()\n",
        "data1= data.data\n",
        "target= data.target\n",
        "df = pd.DataFrame(data1, columns= data.feature_names)\n",
        "\n",
        "\n",
        "df[\"target\"]=data.target\n",
        "\n",
        "x= df.iloc[:,:-1]\n",
        "y=df[\"target\"]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,x_test,y_train,y_test= train_test_split(x,y, test_size = 0.2, random_state=42)\n",
        "x_train.shape,x_test.shape,y_train.shape,y_test.shape\n",
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "param_grid ={'n_estimators':[20,30,40,100],\n",
        "             'criterion':[\"gini\",\"entropy\"],\n",
        "             'max_depth':[2,3,4,5]\n",
        "             }\n",
        "\n",
        "clf= GridSearchCV(estimator=rf,param_grid=param_grid,verbose = 2, cv=5,n_jobs=3)\n",
        "clf.fit(x_train,y_train)\n",
        "best_model= clf.best_estimator_\n",
        "y_pred_tuned=best_model.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import r2_score,mean_squared_error\n",
        "\n",
        "print(r2_score(y_pred_tuned,y_test))\n",
        "\n",
        "\n",
        "#feature importance\n",
        "\n",
        "importances = best_model.feature_importances_\n",
        "feature_names = x.columns\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "importance_df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OAMBv1ilsjLG",
        "outputId": "258089db-f59a-4c8d-b881-007934890f26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
            "0.8476445038422986\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    Feature  Importance\n",
              "23               worst area    0.126228\n",
              "22          worst perimeter    0.125827\n",
              "20             worst radius    0.116173\n",
              "27     worst concave points    0.112920\n",
              "7       mean concave points    0.103727\n",
              "26          worst concavity    0.058606\n",
              "6            mean concavity    0.048632\n",
              "13               area error    0.038570\n",
              "2            mean perimeter    0.031033\n",
              "0               mean radius    0.030633\n",
              "21            worst texture    0.029060\n",
              "10             radius error    0.024164\n",
              "24         worst smoothness    0.023753\n",
              "25        worst compactness    0.019723\n",
              "5          mean compactness    0.012527\n",
              "1              mean texture    0.012155\n",
              "9    mean fractal dimension    0.011381\n",
              "12          perimeter error    0.010938\n",
              "3                 mean area    0.010581\n",
              "16          concavity error    0.009575\n",
              "29  worst fractal dimension    0.007905\n",
              "17     concave points error    0.005682\n",
              "4           mean smoothness    0.005210\n",
              "19  fractal dimension error    0.004870\n",
              "18           symmetry error    0.004257\n",
              "28           worst symmetry    0.004014\n",
              "14         smoothness error    0.003167\n",
              "11            texture error    0.003081\n",
              "15        compactness error    0.002831\n",
              "8             mean symmetry    0.002777"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5e02db40-53d2-4790-a995-3056ea799e94\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>Importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>worst area</td>\n",
              "      <td>0.126228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>worst perimeter</td>\n",
              "      <td>0.125827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>worst radius</td>\n",
              "      <td>0.116173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>worst concave points</td>\n",
              "      <td>0.112920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>mean concave points</td>\n",
              "      <td>0.103727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>worst concavity</td>\n",
              "      <td>0.058606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>mean concavity</td>\n",
              "      <td>0.048632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>area error</td>\n",
              "      <td>0.038570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mean perimeter</td>\n",
              "      <td>0.031033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mean radius</td>\n",
              "      <td>0.030633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>worst texture</td>\n",
              "      <td>0.029060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>radius error</td>\n",
              "      <td>0.024164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>worst smoothness</td>\n",
              "      <td>0.023753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>worst compactness</td>\n",
              "      <td>0.019723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>mean compactness</td>\n",
              "      <td>0.012527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mean texture</td>\n",
              "      <td>0.012155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>mean fractal dimension</td>\n",
              "      <td>0.011381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>perimeter error</td>\n",
              "      <td>0.010938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mean area</td>\n",
              "      <td>0.010581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>concavity error</td>\n",
              "      <td>0.009575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>worst fractal dimension</td>\n",
              "      <td>0.007905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>concave points error</td>\n",
              "      <td>0.005682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mean smoothness</td>\n",
              "      <td>0.005210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>fractal dimension error</td>\n",
              "      <td>0.004870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>symmetry error</td>\n",
              "      <td>0.004257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>worst symmetry</td>\n",
              "      <td>0.004014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>smoothness error</td>\n",
              "      <td>0.003167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>texture error</td>\n",
              "      <td>0.003081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>compactness error</td>\n",
              "      <td>0.002831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>mean symmetry</td>\n",
              "      <td>0.002777</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e02db40-53d2-4790-a995-3056ea799e94')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5e02db40-53d2-4790-a995-3056ea799e94 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5e02db40-53d2-4790-a995-3056ea799e94');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-278cb248-db83-41dc-9c39-66188d87b0af\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-278cb248-db83-41dc-9c39-66188d87b0af')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-278cb248-db83-41dc-9c39-66188d87b0af button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_d419298e-7265-485c-9c58-2f1196446753\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('importance_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d419298e-7265-485c-9c58-2f1196446753 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('importance_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "importance_df",
              "summary": "{\n  \"name\": \"importance_df\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"Feature\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"texture error\",\n          \"mean texture\",\n          \"fractal dimension error\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Importance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0406761855873079,\n        \"min\": 0.0027774801137515808,\n        \"max\": 0.12622756664817048,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          0.003080510579071826,\n          0.01215485696046881,\n          0.004869999556870524\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#30. Train an ensemble model using both Bagging and Random Forest and compare accuracy.\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "x,y = make_classification(n_samples= 1000, n_classes=2,n_informative=4,n_redundant=4, random_state=42 )\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,x_test,y_train,y_test= train_test_split(x,y, test_size = 0.2, random_state=42)\n",
        "x_train.shape,x_test.shape,y_train.shape,y_test.shape\n",
        "\n",
        "\n",
        "#bagging classifier\n",
        "\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "bagging_clf = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(),\n",
        "    n_estimators=50,\n",
        "    random_state=42)\n",
        "\n",
        "bagging_clf.fit(x_train,y_train)\n",
        "y_pred=bagging_clf.predict(x_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report\n",
        "\n",
        "print(accuracy_score(y_pred,y_test))\n",
        "\n",
        "\n",
        "#random forest classifier\n",
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "param_grid ={'n_estimators':[20,30,40,100],\n",
        "             'criterion':[\"gini\",\"entropy\"],\n",
        "             'max_depth':[2,3,4,5]\n",
        "             }\n",
        "\n",
        "clf= GridSearchCV(estimator=rf,param_grid=param_grid,verbose = 2, cv=5,n_jobs=3)\n",
        "clf.fit(x_train,y_train)\n",
        "best_model= clf.best_estimator_\n",
        "y_pred_tuned=best_model.predict(x_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report\n",
        "print(accuracy_score(y_pred_tuned,y_test))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvW0bxSCuVsV",
        "outputId": "dd6e151b-0d15-442a-f70c-1a4dfd006486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.89\n",
            "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
            "0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#31.Train a Random Forest Classifier and tune hyperparameters using GridSearchCV\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "x,y = make_classification(n_samples=1000, n_classes =2, n_redundant = 5, n_informative=5,random_state=42)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y , train_size=0.2,random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "re = RandomForestClassifier()\n",
        "param_grid={\"n_estimators\":[100,20,40,120],\n",
        "            \"max_depth\":[2,4,5,6,7],\n",
        "            \"criterion\":[\"gini\",\"entropy\"]\n",
        "            }\n",
        "model = GridSearchCV(estimator=re,param_grid=param_grid, verbose=2,cv=4,n_jobs=2)\n",
        "\n",
        "model.fit(x_train,y_train)\n",
        "best_model= model.best_estimator_\n",
        "y_pred_tunned=best_model.predict(x_test)\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report\n",
        "print(accuracy_score(y_pred_tunned,y_test))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfQH_Xl6cgQy",
        "outputId": "1105255c-8edb-46d8-88f1-b7a29e98e8b1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
            "0.92125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#32. Train a Bagging Regressor with different numbers of base estimators and compare performance\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "x,y = make_classification(n_samples= 1000,n_informative=4,n_redundant=4, random_state=42 )\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,x_test,y_train,y_test= train_test_split(x,y, test_size = 0.2, random_state=42)\n",
        "x_train.shape,x_test.shape,y_train.shape,y_test.shape\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "\n",
        "\n",
        "\n",
        "estimetor_number = [20,30,50,170,80,110]\n",
        "\n",
        "\n",
        "for n in estimetor_number:\n",
        "    bagging_reg = BaggingRegressor(\n",
        "    estimator=DecisionTreeRegressor(),\n",
        "    n_estimators=n,\n",
        "    random_state=42)\n",
        "\n",
        "    bagging_reg.fit(x_train,y_train)\n",
        "    y_pred_tunned=bagging_reg.predict(x_test)\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    print(f\"the MSE of model when number of estimetor is {n} is {mean_squared_error(y_test,y_pred)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfISEFb1cgMr",
        "outputId": "f6932b68-8000-44ca-9b6a-ec29e88f0ec0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the MSE of model when number of estimetor is 20 is 0.08056200000000001\n",
            "the MSE of model when number of estimetor is 30 is 0.08056200000000001\n",
            "the MSE of model when number of estimetor is 50 is 0.08056200000000001\n",
            "the MSE of model when number of estimetor is 170 is 0.08056200000000001\n",
            "the MSE of model when number of estimetor is 80 is 0.08056200000000001\n",
            "the MSE of model when number of estimetor is 110 is 0.08056200000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#33. Train a Random Forest Classifier and analyze misclassified samples\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "feature_names = data.feature_names\n",
        "target_names = data.target_names\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Accuracy & Confusion Matrix\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=target_names))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Find misclassified samples\n",
        "misclassified_indices = np.where(y_pred != y_test)[0]\n",
        "print(f\"\\nNumber of Misclassified Samples: {len(misclassified_indices)}\")\n",
        "\n",
        "# Create DataFrame of misclassified samples\n",
        "misclassified_samples = pd.DataFrame(X_test[misclassified_indices], columns=feature_names)\n",
        "misclassified_samples['True Label'] = y_test[misclassified_indices]\n",
        "misclassified_samples['Predicted Label'] = y_pred[misclassified_indices]\n",
        "\n",
        "# Show some misclassified samples\n",
        "print(\"\\nMisclassified Samples (first 5):\")\n",
        "print(misclassified_samples.head())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZBfb9EdcgKT",
        "outputId": "b682ccff-16d7-4d81-afa2-3d6e9d82cfac"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9649122807017544\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   malignant       0.98      0.93      0.95        43\n",
            "      benign       0.96      0.99      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.97      0.96      0.96       114\n",
            "weighted avg       0.97      0.96      0.96       114\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[40  3]\n",
            " [ 1 70]]\n",
            "\n",
            "Number of Misclassified Samples: 4\n",
            "\n",
            "Misclassified Samples (first 5):\n",
            "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
            "0        13.34         15.86           86.49      520.0          0.10780   \n",
            "1        13.80         15.79           90.43      584.1          0.10070   \n",
            "2        13.96         17.05           91.43      602.4          0.10960   \n",
            "3        14.48         21.46           94.25      648.2          0.09444   \n",
            "\n",
            "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
            "0           0.15350         0.11690              0.06987         0.1942   \n",
            "1           0.12800         0.07789              0.05069         0.1662   \n",
            "2           0.12790         0.09789              0.05246         0.1908   \n",
            "3           0.09947         0.12040              0.04938         0.2075   \n",
            "\n",
            "   mean fractal dimension  ...  worst perimeter  worst area  worst smoothness  \\\n",
            "0                 0.06902  ...            96.66       614.9            0.1536   \n",
            "1                 0.06566  ...           110.30       812.4            0.1411   \n",
            "2                 0.06130  ...           108.10       826.0            0.1512   \n",
            "3                 0.05636  ...           108.40       808.9            0.1306   \n",
            "\n",
            "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
            "0             0.4791           0.4858                0.1708          0.3527   \n",
            "1             0.3542           0.2779                0.1383          0.2589   \n",
            "2             0.3262           0.3209                0.1374          0.3068   \n",
            "3             0.1976           0.3349                0.1225          0.3020   \n",
            "\n",
            "   worst fractal dimension  True Label  Predicted Label  \n",
            "0                  0.10160           1                0  \n",
            "1                  0.10300           0                1  \n",
            "2                  0.07957           0                1  \n",
            "3                  0.06846           0                1  \n",
            "\n",
            "[4 rows x 32 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#34. Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "data= load_breast_cancer()\n",
        "data1= data.data\n",
        "target= data.target\n",
        "df = pd.DataFrame(data1, columns= data.feature_names)\n",
        "\n",
        "\n",
        "df[\"target\"]=data.target\n",
        "\n",
        "x= df.iloc[:,:-1]\n",
        "y=df[\"target\"]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,x_test,y_train,y_test= train_test_split(x,y, test_size = 0.2, random_state=42)\n",
        "x_train.shape,x_test.shape,y_train.shape,y_test.shape\n",
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "rf = BaggingClassifier()\n",
        "\n",
        "param_grid ={'n_estimators':[20,30,40,100]  }\n",
        "\n",
        "clf= GridSearchCV(estimator=rf,param_grid=param_grid,verbose = 2, cv=5,n_jobs=3)\n",
        "clf.fit(x_train,y_train)\n",
        "best_model= clf.best_estimator_\n",
        "y_pred_tuned=best_model.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "\n",
        "print(accuracy_score(y_pred_tuned,y_test))\n",
        "print(confusion_matrix(y_pred_tuned,y_test))\n",
        "\n",
        "\n",
        "\n",
        "# by single Decision tree\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "reg= DecisionTreeClassifier(max_depth=3,max_leaf_nodes=5,splitter=\"random\",criterion=\"gini\")\n",
        "reg.fit(x_train,y_train)\n",
        "\n",
        "y_pred=reg.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "\n",
        "print(accuracy_score(y_pred_tuned,y_test))\n",
        "print(confusion_matrix(y_pred_tuned,y_test))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "835MvP07cgIC",
        "outputId": "4c6fbcb8-d747-464f-b08c-ffbfb02c9a15"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "0.956140350877193\n",
            "[[40  2]\n",
            " [ 3 69]]\n",
            "0.956140350877193\n",
            "[[40  2]\n",
            " [ 3 69]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#35. train a Random Forest Classifier and visualize the confusion matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "feature_names = data.feature_names\n",
        "target_names = data.target_names\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Accuracy & Confusion Matrix\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=target_names))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgShUCsGcgFA",
        "outputId": "08b5f78a-8c8e-48d0-c9ac-27860e4403ea"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9649122807017544\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   malignant       0.98      0.93      0.95        43\n",
            "      benign       0.96      0.99      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.97      0.96      0.96       114\n",
            "weighted avg       0.97      0.96      0.96       114\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[40  3]\n",
            " [ 1 70]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#36.  Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "feature_names = data.feature_names\n",
        "target_names = data.target_names\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "meta_model= GradientBoostingClassifier()\n",
        "\n",
        "\n",
        "base_model = [(\"logistic\",LogisticRegression()), (\"svc\", SVC()), (\"decision\",DecisionTreeClassifier()),(\"boosting\",AdaBoostClassifier())]\n",
        "\n",
        "clf = StackingClassifier(estimators=base_model,final_estimator= meta_model,cv=5 )\n",
        "\n",
        "\n",
        "clf.fit(x_train,y_train)\n",
        "\n",
        "y_pred= clf.predict(x_test)\n",
        "\n",
        "\n",
        "\n",
        "# Accuracy & Confusion Matrix\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=target_names))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xe1GgVpsq6Jc",
        "outputId": "df776bbe-7f39-44f9-94da-dab9381e8a71"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9824561403508771\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   malignant       0.98      0.98      0.98        43\n",
            "      benign       0.99      0.99      0.99        71\n",
            "\n",
            "    accuracy                           0.98       114\n",
            "   macro avg       0.98      0.98      0.98       114\n",
            "weighted avg       0.98      0.98      0.98       114\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[42  1]\n",
            " [ 1 70]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#37. Train a Random Forest Classifier and print the top 5 most important features\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "importances = rf.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "print(\"Top 5 Important Features:\")\n",
        "for i in range(5):\n",
        "    print(f\"{data.feature_names[indices[i]]}: {importances[indices[i]]:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1P9zNtaq6Hw",
        "outputId": "b0392c1d-8f04-434f-da09-28551bbc529e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Important Features:\n",
            "worst area: 0.1539\n",
            "worst concave points: 0.1447\n",
            "mean concave points: 0.1062\n",
            "worst radius: 0.0780\n",
            "mean concavity: 0.0680\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#38.  Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "bag_clf = BaggingClassifier(n_estimators=50, random_state=42)\n",
        "bag_clf.fit(X_train, y_train)\n",
        "y_pred = bag_clf.predict(X_test)\n",
        "\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdaVDd5Kq6GH",
        "outputId": "89d3b242-e44b-47d8-839b-122008f444d6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9583333333333334\n",
            "Recall: 0.971830985915493\n",
            "F1 Score: 0.965034965034965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#39. Train a Random Forest Classifier and analyze the effect of max_depth on accuracy\n",
        "depths = [2, 4, 6, 8, 10, 20, None]\n",
        "accuracies = []\n",
        "\n",
        "for d in depths:\n",
        "    clf = RandomForestClassifier(max_depth=d, random_state=42)\n",
        "    clf.fit(X_train, y_train)\n",
        "    acc = clf.score(X_test, y_test)\n",
        "    accuracies.append(acc)\n",
        "    print(f\"max_depth={d}: Accuracy={acc:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7wF3ostq6Du",
        "outputId": "3fe1dab1-13a5-4680-a57f-d8360a1f84fa"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_depth=2: Accuracy=0.9649\n",
            "max_depth=4: Accuracy=0.9649\n",
            "max_depth=6: Accuracy=0.9649\n",
            "max_depth=8: Accuracy=0.9649\n",
            "max_depth=10: Accuracy=0.9649\n",
            "max_depth=20: Accuracy=0.9649\n",
            "max_depth=None: Accuracy=0.9649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#40.  Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare performance\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "feature_names = data.feature_names\n",
        "target_names = data.target_names\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Accuracy & Confusion Matrix\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=target_names))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulb5uK1Mq6B_",
        "outputId": "a2281953-1fcc-4abb-a5d0-6891a67749a1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9649122807017544\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   malignant       0.98      0.93      0.95        43\n",
            "      benign       0.96      0.99      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.97      0.96      0.96       114\n",
            "weighted avg       0.97      0.96      0.96       114\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[40  3]\n",
            " [ 1 70]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#41.  Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "y_prob = rf.predict_proba(X_test)[:, 1]\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElpAW_X0q6AL",
        "outputId": "0670ea03-84b7-478a-b0d2-c058f1a527e7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#42. Train a Bagging Classifier and evaluate its performance using cross-validatio\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(bag_clf, X, y, cv=5, scoring='accuracy')\n",
        "print(\"Cross-validation scores:\", scores)\n",
        "print(\"Mean accuracy:\", scores.mean())\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_s9IoaFq5-T",
        "outputId": "2f068712-7a6d-41e4-e5cb-10d747646d15"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.9122807  0.92105263 0.98245614 0.95614035 1.        ]\n",
            "Mean accuracy: 0.9543859649122808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#43. Train a Random Forest Classifier and plot the Precision-Recall curv\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_prob = rf.predict_proba(X_test)[:, 1]\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
        "\n",
        "plt.plot(recall, precision, marker='.')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "r1ao5a-Vq57_",
        "outputId": "549056eb-745b-445a-816b-7d6dd0af3c31"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAATT1JREFUeJzt3XtYVNXeB/DvzDAMoFw07ojiJSUVNVF58RJaCEp5Mk9JaoqU5o3nmBzziKmolVSnDCuV8vV2ei3wlsfSUMSwVLzk7WTeFcMLIFiCgsAws94/PExNDArjzB5wfz/Pw6N7zdprr/1zaL7tvWdvhRBCgIiIiEhGlLaeABEREZHUGICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIiIiEh2GICIiIhIdhiAiIiISHYYgIjIpLFjxyIgIKBe62RlZUGhUCArK8sqc2rs+vfvj/79+xuWL126BIVCgdWrV9tsTkRyxQBE1ECsXr0aCoXC8OPg4ID27dsjLi4OBQUFtp5eg1cdJqp/lEolmjdvjsGDByM7O9vW07OIgoICTJ8+HYGBgXByckKTJk0QHByMt956Czdv3rT19IgaFTtbT4CIjC1YsACtW7dGeXk59uzZg2XLlmHbtm04ceIEnJycJJvH8uXLodfr67XOE088gTt37sDe3t5Ks7q/ESNGICoqCjqdDmfPnsXSpUsxYMAAHDp0CEFBQTab14M6dOgQoqKicPv2bbz00ksIDg4GAPz4449455138P3332PHjh02niVR48EARNTADB48GD169AAAjBs3Do888ggWLVqEf//73xgxYoTJdUpLS9GkSROLzkOtVtd7HaVSCQcHB4vOo766d++Ol156ybDcr18/DB48GMuWLcPSpUttODPz3bx5E8899xxUKhWOHj2KwMBAo9fffvttLF++3CLbssZ7iagh4ikwogbuySefBADk5OQAuHttTtOmTXHhwgVERUXB2dkZo0aNAgDo9XokJyejU6dOcHBwgJeXFyZMmIDffvutxrjffvstwsLC4OzsDBcXF/Ts2RNffPGF4XVT1wClpqYiODjYsE5QUBAWL15seL22a4DWr1+P4OBgODo6wt3dHS+99BKuXr1q1Kd6v65evYqhQ4eiadOm8PDwwPTp06HT6cyuX79+/QAAFy5cMGq/efMmXnvtNfj7+0Oj0aBdu3Z49913axz10uv1WLx4MYKCguDg4AAPDw8MGjQIP/74o6HPqlWr8OSTT8LT0xMajQYdO3bEsmXLzJ7zn3366ae4evUqFi1aVCP8AICXlxdmz55tWFYoFJg3b16NfgEBARg7dqxhufq06+7duzF58mR4enqiRYsW2LBhg6Hd1FwUCgVOnDhhaDt9+jSef/55NG/eHA4ODujRowe2bNnyYDtNZGU8AkTUwFV/cD/yyCOGtqqqKkRGRqJv3754//33DafGJkyYgNWrVyM2NhZ/+9vfkJOTg08++QRHjx7F3r17DUd1Vq9ejZdffhmdOnVCQkIC3NzccPToUaSnp2PkyJEm55GRkYERI0bgqaeewrvvvgsAOHXqFPbu3YupU6fWOv/q+fTs2RNJSUkoKCjA4sWLsXfvXhw9ehRubm6GvjqdDpGRkQgJCcH777+PnTt34oMPPkDbtm0xadIks+p36dIlAECzZs0MbWVlZQgLC8PVq1cxYcIEtGzZEvv27UNCQgLy8vKQnJxs6PvKK69g9erVGDx4MMaNG4eqqir88MMP2L9/v+FI3bJly9CpUyf85S9/gZ2dHb7++mtMnjwZer0eU6ZMMWvef7RlyxY4Ojri+eeff+CxTJk8eTI8PDwwd+5clJaW4umnn0bTpk2xbt06hIWFGfVNS0tDp06d0LlzZwDAzz//jD59+sDPzw8zZ85EkyZNsG7dOgwdOhQbN27Ec889Z5U5Ez0wQUQNwqpVqwQAsXPnTlFYWCguX74sUlNTxSOPPCIcHR3FlStXhBBCxMTECABi5syZRuv/8MMPAoBYu3atUXt6erpR+82bN4Wzs7MICQkRd+7cMeqr1+sNf4+JiRGtWrUyLE+dOlW4uLiIqqqqWvfhu+++EwDEd999J4QQorKyUnh6eorOnTsbbeubb74RAMTcuXONtgdALFiwwGjMxx9/XAQHB9e6zWo5OTkCgJg/f74oLCwU+fn54ocffhA9e/YUAMT69esNfd98803RpEkTcfbsWaMxZs6cKVQqlcjNzRVCCLFr1y4BQPztb3+rsb0/1qqsrKzG65GRkaJNmzZGbWFhYSIsLKzGnFetWnXPfWvWrJno2rXrPfv8EQCRmJhYo71Vq1YiJibGsFz9nuvbt2+Nf9cRI0YIT09Po/a8vDyhVCqN/o2eeuopERQUJMrLyw1ter1e9O7dWzz66KN1njOR1HgKjKiBCQ8Ph4eHB/z9/fHiiy+iadOm+Oqrr+Dn52fU789HRNavXw9XV1cMHDgQRUVFhp/g4GA0bdoU3333HYC7R3Ju3bqFmTNn1rheR6FQ1DovNzc3lJaWIiMjo8778uOPP+L69euYPHmy0baefvppBAYGYuvWrTXWmThxotFyv379cPHixTpvMzExER4eHvD29ka/fv1w6tQpfPDBB0ZHT9avX49+/fqhWbNmRrUKDw+HTqfD999/DwDYuHEjFAoFEhMTa2znj7VydHQ0/L24uBhFRUUICwvDxYsXUVxcXOe516akpATOzs4PPE5txo8fD5VKZdQWHR2N69evG53O3LBhA/R6PaKjowEAv/76K3bt2oXhw4fj1q1bhjreuHEDkZGROHfuXI1TnUQNBU+BETUwS5YsQfv27WFnZwcvLy906NABSqXx/6vY2dmhRYsWRm3nzp1DcXExPD09TY57/fp1AL+fUqs+hVFXkydPxrp16zB48GD4+fkhIiICw4cPx6BBg2pd55dffgEAdOjQocZrgYGB2LNnj1Fb9TU2f9SsWTOja5gKCwuNrglq2rQpmjZtalh+9dVX8cILL6C8vBy7du3CRx99VOMaonPnzuE///lPjW1V+2OtfH190bx581r3EQD27t2LxMREZGdno6yszOi14uJiuLq63nP9+3FxccGtW7ceaIx7ad26dY22QYMGwdXVFWlpaXjqqacA3D391a1bN7Rv3x4AcP78eQghMGfOHMyZM8fk2NevX68R3okaAgYgogamV69ehmtLaqPRaGqEIr1eD09PT6xdu9bkOrV92NeVp6cnjh07hu3bt+Pbb7/Ft99+i1WrVmHMmDFYs2bNA41d7c9HIUzp2bOnIVgBd4/4/PGC30cffRTh4eEAgGeeeQYqlQozZ87EgAEDDHXV6/UYOHAgZsyYYXIb1R/wdXHhwgU89dRTCAwMxKJFi+Dv7w97e3ts27YNH374Yb1vJWBKYGAgjh07hsrKyge6xUBtF5P/8QhWNY1Gg6FDh+Krr77C0qVLUVBQgL1792LhwoWGPtX7Nn36dERGRpocu127dmbPl8iaGICIHhJt27bFzp070adPH5MfaH/sBwAnTpyo94eTvb09hgwZgiFDhkCv12Py5Mn49NNPMWfOHJNjtWrVCgBw5swZw7fZqp05c8bwen2sXbsWd+7cMSy3adPmnv3feOMNLF++HLNnz0Z6ejqAuzW4ffu2ISjVpm3btti+fTt+/fXXWo8Cff3116ioqMCWLVvQsmVLQ3v1KUdLGDJkCLKzs7Fx48Zab4XwR82aNatxY8TKykrk5eXVa7vR0dFYs2YNMjMzcerUKQghDKe/gN9rr1ar71tLooaG1wARPSSGDx8OnU6HN998s8ZrVVVVhg/EiIgIODs7IykpCeXl5Ub9hBC1jn/jxg2jZaVSiS5dugAAKioqTK7To0cPeHp6IiUlxajPt99+i1OnTuHpp5+u0779UZ8+fRAeHm74uV8AcnNzw4QJE7B9+3YcO3YMwN1aZWdnY/v27TX637x5E1VVVQCAv/71rxBCYP78+TX6Vdeq+qjVH2tXXFyMVatW1XvfajNx4kT4+Pjg73//O86ePVvj9evXr+Ott94yLLdt29ZwHVO1zz77rN63EwgPD0fz5s2RlpaGtLQ09OrVy+h0maenJ/r3749PP/3UZLgqLCys1/aIpMQjQEQPibCwMEyYMAFJSUk4duwYIiIioFarce7cOaxfvx6LFy/G888/DxcXF3z44YcYN24cevbsiZEjR6JZs2Y4fvw4ysrKaj2dNW7cOPz666948skn0aJFC/zyyy/4+OOP0a1bNzz22GMm11Gr1Xj33XcRGxuLsLAwjBgxwvA1+ICAAEybNs2aJTGYOnUqkpOT8c477yA1NRWvv/46tmzZgmeeeQZjx45FcHAwSktL8dNPP2HDhg24dOkS3N3dMWDAAIwePRofffQRzp07h0GDBkGv1+OHH37AgAEDEBcXh4iICMORsQkTJuD27dtYvnw5PD09633EpTbNmjXDV199haioKHTr1s3oTtBHjhzBl19+idDQUEP/cePGYeLEifjrX/+KgQMH4vjx49i+fTvc3d3rtV21Wo1hw4YhNTUVpaWleP/992v0WbJkCfr27YugoCCMHz8ebdq0QUFBAbKzs3HlyhUcP378wXaeyFps+RU0Ivpd9VeSDx06dM9+MTExokmTJrW+/tlnn4ng4GDh6OgonJ2dRVBQkJgxY4a4du2aUb8tW7aI3r17C0dHR+Hi4iJ69eolvvzyS6Pt/PFr8Bs2bBARERHC09NT2Nvbi5YtW4oJEyaIvLw8Q58/fw2+Wlpamnj88ceFRqMRzZs3F6NGjTJ8rf9++5WYmCjq8p+q6q+U//Of/zT5+tixY4VKpRLnz58XQghx69YtkZCQINq1ayfs7e2Fu7u76N27t3j//fdFZWWlYb2qqirxz3/+UwQGBgp7e3vh4eEhBg8eLA4fPmxUyy5duggHBwcREBAg3n33XbFy5UoBQOTk5Bj6mfs1+GrXrl0T06ZNE+3btxcODg7CyclJBAcHi7ffflsUFxcb+ul0OvGPf/xDuLu7CycnJxEZGSnOnz9f69fg7/Wey8jIEACEQqEQly9fNtnnwoULYsyYMcLb21uo1Wrh5+cnnnnmGbFhw4Y67ReRLSiEuMcxbyIiIqKHEK8BIiIiItlhACIiIiLZYQAiIiIi2WEAIiIiItlhACIiIiLZYQAiIiIi2eGNEE3Q6/W4du0anJ2d7/l0bCIiImo4hBC4desWfH19azwv8c8YgEy4du0a/P39bT0NIiIiMsPly5fRokWLe/ZhADLB2dkZwN0Curi4WHRsrVaLHTt2GB5TQNbBOkuDdZYG6ywN1lka1qxzSUkJ/P39DZ/j98IAZEL1aS8XFxerBCAnJye4uLjwF8yKWGdpsM7SYJ2lwTpLQ4o61+XyFV4ETURERLLDAERERESywwBEREREssMARERERLLDAERERESywwBEREREssMARERERLLDAERERESywwBEREREssMARERERLJj0wD0/fffY8iQIfD19YVCocDmzZvvu05WVha6d+8OjUaDdu3aYfXq1TX6LFmyBAEBAXBwcEBISAgOHjxo+ckTERFRo2XTAFRaWoquXbtiyZIldeqfk5ODp59+GgMGDMCxY8fw2muvYdy4cdi+fbuhT1paGuLj45GYmIgjR46ga9euiIyMxPXr1621G/WSV1yOc8UK5BWX23oqRPeUV3wH+y4UIa/4jq2n0qA01LqYMy8p9qW2bUg1X1vuoznbb6jvr4eRTR+GOnjwYAwePLjO/VNSUtC6dWt88MEHAIDHHnsMe/bswYcffojIyEgAwKJFizB+/HjExsYa1tm6dStWrlyJmTNnWn4n6mH1vhws+Pok9EKFpae+x4zIDnimq69N5/Swqqqqwq8VwNWbd2Bnp7X1dBqdb45fw3vbz0AvAKUCtb5X5VbnutbF0u5XZ3PmJcW+1LYNqeZb33XMeT/faxv13f6f+ycNC0J0z5Z1mgfVn0IIIWw9CeDuk1u/+uorDB06tNY+TzzxBLp3747k5GRD26pVq/Daa6+huLgYlZWVcHJywoYNG4zGiYmJwc2bN/Hvf//b5LgVFRWoqKgwLJeUlMDf3x9FRUUWexp8XnE5wt7/Hg2i2ERE1OApFUDW35+Aj6uDradiUVqtFhkZGRg4cKDFnwZfUlICd3d3FBcX3/fz26ZHgOorPz8fXl5eRm1eXl4oKSnBnTt38Ntvv0Gn05nsc/r06VrHTUpKwvz582u079ixA05OThaZ+7liBQRUNdpVEFAqLLIJIovQC0CHmm9Kub9XG2pdzJmXFPtS2zaUENBLMF9b7qPqv/+rW5/tmxpLL4B1277Do64P5/86Z2RkWHzMsrKyOvdtVAHIWhISEhAfH29Yrj4CFBERYdEjQEtPfQ/9H97HSgXw3d/DHrp03xBY8/8wHnZ5xeXo/0Hd3qtyqnN96mJp96qzOfOSYl9q28a6V/8Hwz87YPX5mrNOfd/P99oGgHptv7axhkcNeOg+I6x9BKiuGlUA8vb2RkFBgVFbQUEBXFxc4OjoCJVKBZVKZbKPt7d3reNqNBpoNJoa7Wq12mL/OC3d1UgaFoSETT8Znd9t6e5skfHJNEv+G8pF9Xt11qYT0AkBlUKBhcM63/O9Koc6m1MXSzNVZ3PmJcW+1LaNHq3dJZnvg+xjXd/P99tGfbZfPdY/Nv4EAFDI4DPCGv/dqM94jSoAhYaGYtu2bUZtGRkZCA0NBQDY29sjODgYmZmZhmuA9Ho9MjMzERcXJ/V0a4ju2RKhrZth3bbvMDxqwEP9xqbGLbpnSzzR3gOXisoQ4O4EH1dHW0+pQWiodTFnXlLsS23bkGq+ttxHc7Yf3bMlNh25igM5v2J21GO8ANrKbBqAbt++jfPnzxuWc3JycOzYMTRv3hwtW7ZEQkICrl69in/9618AgIkTJ+KTTz7BjBkz8PLLL2PXrl1Yt24dtm7dahgjPj4eMTEx6NGjB3r16oXk5GSUlpYavhVmaz6uDnjUVTx0hzTp4ePj6thgPuAbkoZaF3PmJcW+1LYNqeZry300Z/sa9d1rRd2c7C0yN6qdTQPQjz/+iAEDBhiWq6/DiYmJwerVq5GXl4fc3FzD661bt8bWrVsxbdo0LF68GC1atMD//u//Gr4CDwDR0dEoLCzE3LlzkZ+fj27duiE9Pb3GhdFEREQkXzYNQP3798e9voVv6i7P/fv3x9GjR+85blxcXIM45UVEREQNE58FRkRERLLDAERERESywwBEREREssMARERE9BDiQ1rvrVHdB4iIiOhhVqHVAQBullXWeC2v+A5yikrR2r3Jfb9an3Yot8aNd6vvK3Sv14QQqKjS//dHh8oqPb46ehWLMs5CPGQPaWUAIiIiagDSDuXiQM6vAIC3tp6CSqVAVJAPKrR6fHX0Cj7ceQ5C3L1LdExoK/QMeAQVVTqUa/VGfxbdrsTa/b8YHr6tF8A/Nv6EjYevoLJK4NiVm4ZtVr+24OuT0OoEKnX6e85RL4BZm07gifYeDfJ+WPXBAERERGRjecV3kLDpJ8OyADBvy0nM23KyRl8hgNX7fsHqfb/UaxsHL/1W62ullboabQoFYKdUQKszvl2NTghcKipjACIiIqIHk1NUavQg1D+yVylNHpkJ9HKGh4sGGjsVHNRKw59VOoF1P17GH4dTKIC5zzwGezsVZm8+AfGnh66mvvo/aNHMCRo7JTRqFexVSqhVCuSXlKPPO7uM5qZSKBDg7mSZHbchBiAiIiIba+3eBEoFajwNfs8/BkChUJgMIate7lnrUZjurdxqPIi1+rodO6Wixmu9Wj9ichwfV0ckDQvCzI0/QQBQAFg4rHOjP/oDMAARERHZXHXQ+HMw8XW7e6TF1Gv3CiGWfkjrD+cK8c1/8jEhrM1DcQE0wABERETUIFgytACWfUirk/3duODsoK7zOg0dAxAREVEDYcnQQvfGGyESERGR7DAAERERkewwABEREZHsMAARERHRPZVVVgEAbpVrbTwTy2EAIiIiolqlHcrFN//JBwB8uvsi0g7l2nhGlsEARERERCaZekTHrE0nHoqnwjMAERERkUmmHtFR/Sywxo4BiIiIiEyqfkTHHykVeCieBcYARERERCZVP6JDpfg9BbVo5ghvFwcbzsoyGICIiIioVtE9W2LPzAFYOqo7HOyUyP31Drb/XGDraT0wBiAiIiK6Jx9XR0QF+WD8E20AAO+ln4ZWp7fxrB4MAxARERHVyatPtEHzJva4WFSKtEOXbT2dB8IARERERHXi7KDG1KceBQAk7zyH0ooqG8/IfAxAREREVGcjerVEq0ecUHS7Ast/uGjr6ZiNAYiIiIjqzN5OiRmRgQCAz76/iMJbFfVaP6+4HOeKFcgrLrfG9OqMAYiIiIjqJSrIG1393VBWqUPStlPYd6Goxt2h84rv1GhPO5SL/h98j09OqtD/g+9t+lgNO5ttmYiIiBolhUKBhMGBePGz/dh09Co2Hb0KpQKYENYGj/s3w/af87HpyFVU30T6MW9nKJUK/HytxDCGXtx9rMYT7T3g4+oo+T4wABEREVG9tXrE+G7QegEsyzJ9TdCp/Fsm26sfq2GLAMRTYERERFRvOUWlJtt9XU3fJXp8v9ZQ/OmxGiqFwmaP1WAAIiIionoz9ZwwlUKBZS91N9n+ct/WeGdYEKpfUgBYOKyzTY7+AAxAREREZIY/PydMpVBg4bDO6OrfzGS7j6sjonu2xPPdfQEAo0L8Ed2zpc3mb/MAtGTJEgQEBMDBwQEhISE4ePBgrX21Wi0WLFiAtm3bwsHBAV27dkV6erpRn3nz5kGhUBj9BAYGWns3iIiIZKf6OWFfjv8f7Jk5wBBoamsHgCaau5cfN9XY9jJkm249LS0N8fHxSElJQUhICJKTkxEZGYkzZ87A09OzRv/Zs2fj//7v/7B8+XIEBgZi+/bteO6557Bv3z48/vjjhn6dOnXCzp07Dct2drzWm4iIyBp8XB1Nnsaqrb2hsOkRoEWLFmH8+PGIjY1Fx44dkZKSAicnJ6xcudJk/88//xyzZs1CVFQU2rRpg0mTJiEqKgoffPCBUT87Ozt4e3sbftzd3aXYHSIiImokbHZopLKyEocPH0ZCQoKhTalUIjw8HNnZ2SbXqaiogIOD8dXljo6O2LNnj1HbuXPn4OvrCwcHB4SGhiIpKQktW9Z+nrGiogIVFb/fybKk5O59CrRaLbRabb337V6qx7P0uGSMdZYG6ywN1lkarLM09Pq7T5HX6XRW+4ytC4UQQty/m+Vdu3YNfn5+2LdvH0JDQw3tM2bMwO7du3HgwIEa64wcORLHjx/H5s2b0bZtW2RmZuLZZ5+FTqczBJhvv/0Wt2/fRocOHZCXl4f58+fj6tWrOHHiBJydnU3OZd68eZg/f36N9i+++AJOTrb5eh4REdHD6MsLSuy/rkRfbz1eaK236NhlZWUYOXIkiouL4eLics++jerimMWLF2P8+PEIDAyEQqFA27ZtERsba3TKbPDgwYa/d+nSBSEhIWjVqhXWrVuHV155xeS4CQkJiI+PNyyXlJTA398fERER9y1gfWm1WmRkZGDgwIFQq9UWHZt+xzpLg3WWBussDdbZ+tYfvoID2ScBAHvzlYj6n854IbiFxcavPoNTFzYLQO7u7lCpVCgoKDBqLygogLe3t8l1PDw8sHnzZpSXl+PGjRvw9fXFzJkz0aZNm1q34+bmhvbt2+P8+fO19tFoNNBoNDXa1Wq11X4JrDk2/Y51lgbrLA3WWRqss3XkFd/B7H+fNDweQwCY8+9TGPCYt8Uulq7Pv5vNLoK2t7dHcHAwMjMzDW16vR6ZmZlGp8RMcXBwgJ+fH6qqqrBx40Y8++yztfa9ffs2Lly4AB8fH4vNnYiIiOonp6gU+j9ddFP9KAxbsOm3wOLj47F8+XKsWbMGp06dwqRJk1BaWorY2FgAwJgxY4wukj5w4AA2bdqEixcv4ocffsCgQYOg1+sxY8YMQ5/p06dj9+7duHTpEvbt24fnnnsOKpUKI0aMkHz/iIiI6K7a7hxtq0dh2PQaoOjoaBQWFmLu3LnIz89Ht27dkJ6eDi8vLwBAbm4ulMrfM1p5eTlmz56NixcvomnTpoiKisLnn38ONzc3Q58rV65gxIgRuHHjBjw8PNC3b1/s378fHh4eUu8eERER/Vf1naNnbvwJArZ/FIbNL4KOi4tDXFycydeysrKMlsPCwnDy5Ml7jpeammqpqREREZEFRfdsiR9zbmD9kWt8FAYRERHJR0N5FAYDEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERFJprSiCgBw+79/2goDEBEREUki7VAuNhy5BgBYe+Ay0g7l2mwuDEBERERkdXnFd5Cw6SejZ4HN2nQCecV3bDIfBiAiIiKyOj4LjIiIiGSnoT0LjAGIiIiIrK76WWDVGcjWzwJjACIiIiJJRPdsiee7+wIAnwVGRERE8sFngRERERHZCAMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERSaa0ogoAcPu/f9oKAxARERFJIu1QLjYcuQYAWHvgMtIO5dpsLgxAREREZHV5xXeQsOkniP8uCwCzNp1AXvEdm8yHAYiIiIisLqeoFHph3KYTApeKymwyHwYgIiIisrrW7k2gVBi3qRQKBLg72WQ+DEBERERkdT6ujkgaFoTqDKQAsHBYZ/i4OtpkPgxAREREJInoni3xfHdfAMCoEH9E92xps7kwABEREZFkmmjsAABN//unrdg8AC1ZsgQBAQFwcHBASEgIDh48WGtfrVaLBQsWoG3btnBwcEDXrl2Rnp7+QGMSERGR/Ng0AKWlpSE+Ph6JiYk4cuQIunbtisjISFy/ft1k/9mzZ+PTTz/Fxx9/jJMnT2LixIl47rnncPToUbPHJCIiIvmxaQBatGgRxo8fj9jYWHTs2BEpKSlwcnLCypUrTfb//PPPMWvWLERFRaFNmzaYNGkSoqKi8MEHH5g9JhEREUmnodwJ2mYn4CorK3H48GEkJCQY2pRKJcLDw5GdnW1ynYqKCjg4OBi1OTo6Ys+ePWaPWT1uRUWFYbmkpATA3VNuWq22/jt3D9XjWXpcMsY6S4N1lgbrLA3W2frWH75idCfojj7OeCG4hcXGr8+/nc0CUFFREXQ6Hby8vIzavby8cPr0aZPrREZGYtGiRXjiiSfQtm1bZGZmYtOmTdDpdGaPCQBJSUmYP39+jfYdO3bAyck69yfIyMiwyrhkjHWWBussDdZZGqyzddysAOYdUUH894vwAsAbm3+GNvc/cNNYZhtlZXW/qaJtL8Gup8WLF2P8+PEIDAyEQqFA27ZtERsb+8CntxISEhAfH29YLikpgb+/PyIiIuDi4vKg0zai1WqRkZGBgQMHQq1WW3Rs+h3rLA3WWRqsszRYZ+vaf/FXiCM/GrUJKNC22/8gpHVzi2yj+gxOXdgsALm7u0OlUqGgoMCovaCgAN7e3ibX8fDwwObNm1FeXo4bN27A19cXM2fORJs2bcweEwA0Gg00mprxU61WW+2XwJpj0+9YZ2mwztJgnaXBOltHO28XKBUwehyGSqFAWy8Xi9W7PuPY7CJoe3t7BAcHIzMz09Cm1+uRmZmJ0NDQe67r4OAAPz8/VFVVYePGjXj22WcfeEwiIiKynoZ2J2ibngKLj49HTEwMevTogV69eiE5ORmlpaWIjY0FAIwZMwZ+fn5ISkoCABw4cABXr15Ft27dcPXqVcybNw96vR4zZsyo85hERERkG9E9W+LHnBtYf+Saze8EbdMAFB0djcLCQsydOxf5+fno1q0b0tPTDRcx5+bmQqn8/SBVeXk5Zs+ejYsXL6Jp06aIiorC559/Djc3tzqPSURERLbTUO4EbfOLoOPi4hAXF2fytaysLKPlsLAwnDx58oHGJCIiIrL5ozCIiIiIpMYARERERJJpKHeCZgAiIiIiSaQdyjW6E3TaoVybzYUBiIiIiKwur/gOEjb9hOrbAAkAszadQF7xHZvMhwGIiIiIrC6nqNToJogAoBMCl4rq/vgKS2IAIiIiIqtr7d4ESoVxm0qhQIC7dZ65eT8MQERERGR1De1O0AxAREREJInoni3xfHdfALD5naAZgIiIiEgyDeVO0AxAREREJDsMQERERCQ7DEBEREQkGd4JmoiIiGSFd4ImIiIiWeGdoImIiEh2eCdoIiIikh3eCZqIiIhkh3eCJiIiIlninaCJiIhIlngnaCIiIiIbYQAiIiIiyfBGiERERCQrvBEiERERyQpvhEhERESywxshEhERkezwRohEREQkO7wRIhEREckSb4RIREREssQbIRIRERHZCAMQERERyQ4DEBEREckOAxARERHJDgMQERERyY7NA9CSJUsQEBAABwcHhISE4ODBg/fsn5ycjA4dOsDR0RH+/v6YNm0aysvLDa/PmzcPCoXC6CcwMNDau0FERESNiE2/g5aWlob4+HikpKQgJCQEycnJiIyMxJkzZ+Dp6Vmj/xdffIGZM2di5cqV6N27N86ePYuxY8dCoVBg0aJFhn6dOnXCzp07Dct2drb9qh0RERE1LDY9ArRo0SKMHz8esbGx6NixI1JSUuDk5ISVK1ea7L9v3z706dMHI0eOREBAACIiIjBixIgaR43s7Ozg7e1t+HF3d5did4iIiKiRsFkAqqysxOHDhxEeHv77ZJRKhIeHIzs72+Q6vXv3xuHDhw2B5+LFi9i2bRuioqKM+p07dw6+vr5o06YNRo0ahdzcXOvtCBERETU6Njs3VFRUBJ1OBy8vL6N2Ly8vnD592uQ6I0eORFFREfr27QshBKqqqjBx4kTMmjXL0CckJASrV69Ghw4dkJeXh/nz56Nfv344ceIEnJ2dTY5bUVGBiooKw3JJSQkAQKvVQqvVPuiuGqkez9LjkjHWWRqsszRYZ2mwztLQ6/UAAJ1OZ7XP2LpoVBfHZGVlYeHChVi6dClCQkJw/vx5TJ06FW+++SbmzJkDABg8eLChf5cuXRASEoJWrVph3bp1eOWVV0yOm5SUhPnz59do37FjB5ycrPOU2oyMDKuMS8ZYZ2mwztJgnaXBOlvXL7lKAErkXLqEbdsuWnTssrKyOve1WQByd3eHSqVCQUGBUXtBQQG8vb1NrjNnzhyMHj0a48aNAwAEBQWhtLQUr776Kt544w0olTXP6Lm5uaF9+/Y4f/58rXNJSEhAfHy8YbmkpAT+/v6IiIiAi4uLObtXK61Wi4yMDAwcOBBqtdqiY9PvWGdpsM7SYJ2lwTpL4/A3J4G8K2gdEICoQZb9lnb1GZy6sFkAsre3R3BwMDIzMzF06FAAdw+LZWZmIi4uzuQ6ZWVlNUKOSqUCAAghTK5z+/ZtXLhwAaNHj651LhqNBhqNpka7Wq222i+BNcem37HO0mCdpcE6S4N1tq7qz3GVSmXxOtdnPJueAouPj0dMTAx69OiBXr16ITk5GaWlpYiNjQUAjBkzBn5+fkhKSgIADBkyBIsWLcLjjz9uOAU2Z84cDBkyxBCEpk+fjiFDhqBVq1a4du0aEhMToVKpMGLECJvtJxERETUsNg1A0dHRKCwsxNy5c5Gfn49u3bohPT3dcGF0bm6u0RGf2bNnQ6FQYPbs2bh69So8PDwwZMgQvP3224Y+V65cwYgRI3Djxg14eHigb9++2L9/Pzw8PCTfPyIiImqYbH4RdFxcXK2nvLKysoyW7ezskJiYiMTExFrHS01NteT0iIiI6CFk80dhEBEREUnNrCNAOp0Oq1evRmZmJq5fv274Tn+1Xbt2WWRyRERERNZgVgCaOnUqVq9ejaeffhqdO3eGQqGw9LyIiIiIrMasAJSamop169bVeAQFERERUWNg1jVA9vb2aNeunaXnQkRERCQJswLQ3//+dyxevLjWmw8SERERNWRmnQLbs2cPvvvuO3z77bfo1KlTjTsvbtq0ySKTIyIiIrIGswKQm5sbnnvuOUvPhYiIiEgSZgWgVatWWXoeRERERJJ5oDtBFxYW4syZMwCADh068HETRERE1CiYdRF0aWkpXn75Zfj4+OCJJ57AE088AV9fX7zyyisoKyuz9ByJiIiILMqsABQfH4/du3fj66+/xs2bN3Hz5k38+9//xu7du/H3v//d0nMkIiIisiizToFt3LgRGzZsQP/+/Q1tUVFRcHR0xPDhw7Fs2TJLzY+IiIgeIqUVVQCA2//901bMOgJUVlYGLy+vGu2enp48BUZEREQmpR3KxYYj1wAAaw9cRtqhXJvNxawAFBoaisTERJSXlxva7ty5g/nz5yM0NNRikyMiIqKHQ17xHSRs+gnVt1AWAGZtOoG84js2mY9Zp8AWL16MyMhItGjRAl27dgUAHD9+HA4ODti+fbtFJ0hERESNX05RKfR/eoCETghcKiqDj6uj5PMxKwB17twZ586dw9q1a3H69GkAwIgRIzBq1Cg4Okq/E0RERNSwtXZvAqUCRiFIpVAgwN3JJvMx+z5ATk5OGD9+vCXnQkRERA8pH1dHJA0LwsyNd0+DKQAsHNbZJkd/gHoEoC1btmDw4MFQq9XYsmXLPfv+5S9/eeCJERER0cMlumdL/JhzA+uPXMOoEH9E92xps7nUOQANHToU+fn58PT0xNChQ2vtp1AooNPpLDE3IiIiesg00dyNHk01D/QwigdW563r9XqTfyciIiJqbMz6GrwpN2/etNRQRERERFZlVgB69913kZaWZlh+4YUX0Lx5c/j5+eH48eMWmxwRERGRNZgVgFJSUuDv7w8AyMjIwM6dO5Geno7Bgwfj9ddft+gEiYiIiCzNrCuQ8vPzDQHom2++wfDhwxEREYGAgACEhIRYdIJERERElmbWEaBmzZrh8uXLAID09HSEh4cDAIQQ/AYYERERNXhmHQEaNmwYRo4ciUcffRQ3btzA4MGDAQBHjx5Fu3btLDpBIiIiIkszKwB9+OGHCAgIwOXLl/Hee++hadOmAIC8vDxMnjzZohMkIiIisjSzApBarcb06dNrtE+bNu2BJ0RERERkbXwUBhEREckOH4VBREREssNHYRAREZHsWOxRGERERESNhVkB6G9/+xs++uijGu2ffPIJXnvttQedExEREZFVmRWANm7ciD59+tRo7927NzZs2FCvsZYsWYKAgAA4ODggJCQEBw8evGf/5ORkdOjQAY6OjvD398e0adNQXl7+QGMSERGRvJgVgG7cuAFXV9ca7S4uLigqKqrzOGlpaYiPj0diYiKOHDmCrl27IjIyEtevXzfZ/4svvsDMmTORmJiIU6dOYcWKFUhLS8OsWbPMHpOIiIjkx6wA1K5dO6Snp9do//bbb9GmTZs6j7No0SKMHz8esbGx6NixI1JSUuDk5ISVK1ea7L9v3z706dMHI0eOREBAACIiIjBixAijIzz1HZOIiIjkx6wbIcbHxyMuLg6FhYV48sknAQCZmZn44IMPkJycXKcxKisrcfjwYSQkJBjalEolwsPDkZ2dbXKd3r174//+7/9w8OBB9OrVCxcvXsS2bdswevRos8cEgIqKClRUVBiWS0pKAABarRZarbZO+1NX1eNZelwyxjpLg3WWBussDdZZGtXfJNfpdFb7jK0LswLQyy+/jIqKCrz99tt48803AQABAQFYtmwZxowZU6cxioqKoNPp4OXlZdTu5eWF06dPm1xn5MiRKCoqQt++fSGEQFVVFSZOnGg4BWbOmACQlJSE+fPn12jfsWMHnJyc6rQ/9ZWRkWGVcckY6ywN1lkarLM0WGfr+iVXCUCJnEuXsG3bRYuOXVZWVue+ZgUgAJg0aRImTZqEwsJCODo6Gp4HZk1ZWVlYuHAhli5dipCQEJw/fx5Tp07Fm2++iTlz5pg9bkJCAuLj4w3LJSUl8Pf3R0REBFxcXCwxdQOtVouMjAwMHDgQarXaomPT71hnabDO0mCdpcE6S+PwNyeBvCtoHRCAqEGBFh27+gxOXZgdgKqqqpCVlYULFy5g5MiRAIBr167BxcWlTmHI3d0dKpUKBQUFRu0FBQXw9vY2uc6cOXMwevRojBs3DgAQFBSE0tJSvPrqq3jjjTfMGhMANBoNNBpNjXa1Wm21XwJrjk2/Y52lwTpLg3WWButsXUrl3cuPVSqVxetcn/HMugj6l19+QVBQEJ599llMmTIFhYWFAIB3333X5ENSTbG3t0dwcDAyMzMNbXq9HpmZmQgNDTW5TllZmaFw1VQqFQBACGHWmERERCQ/ZgWgqVOnokePHvjtt9/g6OhoaH/uueeMwsf9xMfHY/ny5VizZg1OnTqFSZMmobS0FLGxsQCAMWPGGF3QPGTIECxbtgypqanIyclBRkYG5syZgyFDhhiC0P3GJCIiIjLrFNgPP/yAffv2wd7e3qg9ICAAV69erfM40dHRKCwsxNy5c5Gfn49u3bohPT3dcBFzbm6u0RGf2bNnQ6FQYPbs2bh69So8PDwwZMgQvP3223Uek4iIiMisAKTX600+8f3KlStwdnau11hxcXGIi4sz+VpWVpbRsp2dHRITE5GYmGj2mERERERmnQKLiIgwut+PQqHA7du3kZiYiKioKEvNjYiIiMgqzDoC9P7772PQoEHo2LEjysvLMXLkSJw7dw7u7u748ssvLT1HIiIiIosyKwD5+/vj+PHjSEtLw/Hjx3H79m288sorGDVqlNFF0UREREQNUb0DkFarRWBgIL755huMGjUKo0aNssa8iIiIiKym3tcAqdVqlJeXW2MuRERERJIw6yLoKVOm4N1330VVVZWl50NERERkdWZdA3To0CFkZmZix44dCAoKQpMmTYxe37Rpk0UmR0RERGQNZgUgNzc3/PWvf7X0XIiIiIgkUa8ApNfr8c9//hNnz55FZWUlnnzyScybN4/f/CIiIqJGpV7XAL399tuYNWsWmjZtCj8/P3z00UeYMmWKteZGREREZBX1CkD/+te/sHTpUmzfvh2bN2/G119/jbVr10Kv11trfkREREQWV68AlJuba/Soi/DwcCgUCly7ds3iEyMiIiKylnoFoKqqKjg4OBi1qdVqaLVai06KiIiIyJrqdRG0EAJjx46FRqMxtJWXl2PixIlGX4Xn1+CJiIioIatXAIqJianR9tJLL1lsMkRERERSqFcAWrVqlbXmQURERDJQWnH3KRK3K2z7NAmzHoVBREREVF9ph3Kx4cjdL06tPXAZaYdybTYXBiAiIiKyurziO0jY9BPEf5cFgFmbTiCv+I5N5sMARERERFaXU1QKvTBu0wmBS0VlNpkPAxARERFZXWv3JlAqjNtUCgUC3J1sMh8GICIiIrI6H1dHJA0LQnUGUgBYOKwzfFxt8zxRBiAiIiKSRHTPlni+uy8AYFSIP6J7trTZXBiAiIiISDJNNHfvwNNUU6878VgcAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJToMIQEuWLEFAQAAcHBwQEhKCgwcP1tq3f//+UCgUNX6efvppQ5+xY8fWeH3QoEFS7AoRERE1ArZ9EAeAtLQ0xMfHIyUlBSEhIUhOTkZkZCTOnDkDT0/PGv03bdqEyspKw/KNGzfQtWtXvPDCC0b9Bg0ahFWrVhmWNRqN9XaCiIiIGhWbHwFatGgRxo8fj9jYWHTs2BEpKSlwcnLCypUrTfZv3rw5vL29DT8ZGRlwcnKqEYA0Go1Rv2bNmkmxO0RERNQI2DQAVVZW4vDhwwgPDze0KZVKhIeHIzs7u05jrFixAi+++CKaNGli1J6VlQVPT0906NABkyZNwo0bNyw6dyIiImq8bHoKrKioCDqdDl5eXkbtXl5eOH369H3XP3jwIE6cOIEVK1YYtQ8aNAjDhg1D69atceHCBcyaNQuDBw9GdnY2VCpVjXEqKipQUVFhWC4pKQEAaLVaaLVac3atVtXjWXpcMsY6S4N1lgbrLA3WWRp6vR4AoNPprPYZWxc2vwboQaxYsQJBQUHo1auXUfuLL75o+HtQUBC6dOmCtm3bIisrC0899VSNcZKSkjB//vwa7Tt27ICTk5PlJw4gIyPDKuOSMdZZGqyzNFhnabDO1vVLrhKAEjmXLmHbtosWHbusrKzOfW0agNzd3aFSqVBQUGDUXlBQAG9v73uuW1paitTUVCxYsOC+22nTpg3c3d1x/vx5kwEoISEB8fHxhuWSkhL4+/sjIiICLi4uddybutFqtcjIyMDAgQOhVqstOjb9jnWWBussDdZZGqyzNA5/cxLIu4LWAQGIGhRo0bGrz+DUhU0DkL29PYKDg5GZmYmhQ4cCuHtoLDMzE3Fxcfdcd/369aioqMBLL7103+1cuXIFN27cgI+Pj8nXNRqNyW+JqdVqq/0SWHNs+h3rLA3WWRqsszRYZ+tSKu9efqxSqSxe5/qMZ/NvgcXHx2P58uVYs2YNTp06hUmTJqG0tBSxsbEAgDFjxiAhIaHGeitWrMDQoUPxyCOPGLXfvn0br7/+Ovbv349Lly4hMzMTzz77LNq1a4fIyEhJ9omIiIgaNptfAxQdHY3CwkLMnTsX+fn56NatG9LT0w0XRufm5hrSYrUzZ85gz5492LFjR43xVCoV/vOf/2DNmjW4efMmfH19ERERgTfffJP3AiIiIiIADSAAAUBcXFytp7yysrJqtHXo0AFCCJP9HR0dsX37dktOj4iIiB4yNj8FRkRERCQ1BiAiIiKSHQYgIiIikh0GICIiIpIdBiAiIiKSHQYgIiIikh0GICIiIpIdBiAiIiKSHQYgIiIikh0GICIiIpIdBiAiIiKSHQYgIiIikh0GICIiIpIdBiAiIiKSHQYgIiIikh0GICIiIpIdBiAiIiKSHQYgIiIikh0GICIiIpIdBiAiIiKSHQYgIiIikh0GICIiIpIdBiAiIiKSHQYgIiIikh0GICIiIpIdBiAiIiKSHQYgIiIikh0GICIiIpIdBiAiIiKSHQYgIiIikh0GICIiIpIdBiAiIiKSHQYgIiIikh0GICIiIpKdBhGAlixZgoCAADg4OCAkJAQHDx6stW///v2hUChq/Dz99NOGPkIIzJ07Fz4+PnB0dER4eDjOnTsnxa4QERFRI2DzAJSWlob4+HgkJibiyJEj6Nq1KyIjI3H9+nWT/Tdt2oS8vDzDz4kTJ6BSqfDCCy8Y+rz33nv46KOPkJKSggMHDqBJkyaIjIxEeXm5VLtFREREDZjNA9CiRYswfvx4xMbGomPHjkhJSYGTkxNWrlxpsn/z5s3h7e1t+MnIyICTk5MhAAkhkJycjNmzZ+PZZ59Fly5d8K9//QvXrl3D5s2bJdwzIiIiaqjsbLnxyspKHD58GAkJCYY2pVKJ8PBwZGdn12mMFStW4MUXX0STJk0AADk5OcjPz0d4eLihj6urK0JCQpCdnY0XX3yxxhgVFRWoqKgwLJeUlAAAtFottFqtWftWm+rxLD0uGWOdpcE6S4N1lgbrLA29Xg8A0Ol0VvuMrQubBqCioiLodDp4eXkZtXt5eeH06dP3Xf/gwYM4ceIEVqxYYWjLz883jPHnMatf+7OkpCTMnz+/RvuOHTvg5OR033mYIyMjwyrjkjHWWRqsszRYZ2mwztb1S64SgBI5ly5h27aLFh27rKyszn1tGoAe1IoVKxAUFIRevXo90DgJCQmIj483LJeUlMDf3x8RERFwcXF50Gka0Wq1yMjIwMCBA6FWqy06Nv2OdZYG6ywN1lkarLM0Dn9zEsi7gtYBAYgaFGjRsavP4NSFTQOQu7s7VCoVCgoKjNoLCgrg7e19z3VLS0uRmpqKBQsWGLVXr1dQUAAfHx+jMbt162ZyLI1GA41GU6NdrVZb7ZfAmmPT71hnabDO0mCdpcE6W5dSeffyY5VKZfE612c8m14EbW9vj+DgYGRmZhra9Ho9MjMzERoaes91169fj4qKCrz00ktG7a1bt4a3t7fRmCUlJThw4MB9xyQiIiJ5sPkpsPj4eMTExKBHjx7o1asXkpOTUVpaitjYWADAmDFj4Ofnh6SkJKP1VqxYgaFDh+KRRx4xalcoFHjttdfw1ltv4dFHH0Xr1q0xZ84c+Pr6YujQoVLtFhERETVgNg9A0dHRKCwsxNy5c5Gfn49u3bohPT3dcBFzbm6u4XBZtTNnzmDPnj3YsWOHyTFnzJiB0tJSvPrqq7h58yb69u2L9PR0ODg4WH1/iIiIqOGzeQACgLi4OMTFxZl8LSsrq0Zbhw4dIISodTyFQoEFCxbUuD6IiIiICGgAN0IkIiIikhoDEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJjs0D0JIlSxAQEAAHBweEhITg4MGD9+x/8+ZNTJkyBT4+PtBoNGjfvj22bdtmeH3evHlQKBRGP4GBgdbeDSIiImpE7Gy58bS0NMTHxyMlJQUhISFITk5GZGQkzpw5A09Pzxr9KysrMXDgQHh6emLDhg3w8/PDL7/8Ajc3N6N+nTp1ws6dOw3LdnY23U0iIiJqYGyaDBYtWoTx48cjNjYWAJCSkoKtW7di5cqVmDlzZo3+K1euxK+//op9+/ZBrVYDAAICAmr0s7Ozg7e3t1XnTkRERI2XzU6BVVZW4vDhwwgPD/99MkolwsPDkZ2dbXKdLVu2IDQ0FFOmTIGXlxc6d+6MhQsXQqfTGfU7d+4cfH190aZNG4waNQq5ublW3RciIiJqXGx2BKioqAg6nQ5eXl5G7V5eXjh9+rTJdS5evIhdu3Zh1KhR2LZtG86fP4/JkydDq9UiMTERABASEoLVq1ejQ4cOyMvLw/z589GvXz+cOHECzs7OJsetqKhARUWFYbmkpAQAoNVqodVqLbG7BtXjWXpcMsY6S4N1lgbrLA3WWRp6vR4AoNPprPYZWxcKIYSw6Nbr6Nq1a/Dz88O+ffsQGhpqaJ8xYwZ2796NAwcO1Finffv2KC8vR05ODlQqFYC7p9H++c9/Ii8vz+R2bt68iVatWmHRokV45ZVXTPaZN28e5s+fX6P9iy++gJOTkzm7R0RERCZsuqTE7jwlwv30GNJSb9Gxy8rKMHLkSBQXF8PFxeWefW12BMjd3R0qlQoFBQVG7QUFBbVev+Pj4wO1Wm0IPwDw2GOPIT8/H5WVlbC3t6+xjpubG9q3b4/z58/XOpeEhATEx8cblktKSuDv74+IiIj7FrC+tFotMjIyMHDgQMN1TGR5rLM0WGdpsM7SYJ2lcfibk0DeFbQOCEDUIMt+S7v6DE5d2CwA2dvbIzg4GJmZmRg6dCiAu4fFMjMzERcXZ3KdPn364IsvvoBer4dSeffypbNnz8LHx8dk+AGA27dv48KFCxg9enStc9FoNNBoNDXa1Wq11X4JrDk2/Y51lgbrLA3WWRqss3VVf36rVCqL17k+49n0PkDx8fFYvnw51qxZg1OnTmHSpEkoLS01fCtszJgxSEhIMPSfNGkSfv31V0ydOhVnz57F1q1bsXDhQkyZMsXQZ/r06di9ezcuXbqEffv24bnnnoNKpcKIESMk3z8iIiJqmGz6Nfjo6GgUFhZi7ty5yM/PR7du3ZCenm64MDo3N9eQFAHA398f27dvx7Rp09ClSxf4+flh6tSp+Mc//mHoc+XKFYwYMQI3btyAh4cH+vbti/3798PDw0Py/SMiIqKGyeZ3CIyLi6v1lFdWVlaNttDQUOzfv7/W8VJTUy01NSIiInpI2fxRGERERERSYwAiIiIi2WEAIiIiItlhACIiIiLZYQAiIiIi2WEAIiIiItlhACIiIiLZYQAiIiIi2WEAIiIiItlhACIiIiLZYQAiIiIi2WEAIiIiItlhACIiIiLZYQAiIiIi2WEAIiIiItlhACIiIiLJlFZUAQBu//dPW2EAIiIiIkmkHcrFhiPXAABrD1xG2qFcm82FAYiIiIisLq/4DhI2/QTx32UBYNamE8grvmOT+TAAERERkdXlFJVCL4zbdELgUlGZTebDAERERERW19q9CZQK4zaVQoEAdyebzIcBiIiIiKzOx9URScOCDCFIqQAWDusMH1dHm8zHziZbJSIiItmJ7tkSoa2bYd227zA8agBaujvbbC48AkRERESS8XF1wKOuAj6uDjadBwMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOAxARERHJDgMQERERyQ4DEBEREckOH4ZqghACAFBSUmLxsbVaLcrKylBSUgK1Wm3x8eku1lkarLM0WGdpsM7SsGadqz+3qz/H74UByIRbt24BAPz9/W08EyIiIqqvW7duwdXV9Z59FKIuMUlm9Ho9rl27BmdnZygUCouOXVJSAn9/f1y+fBkuLi4WHZt+xzpLg3WWBussDdZZGtassxACt27dgq+vL5TKe1/lwyNAJiiVSrRo0cKq23BxceEvmARYZ2mwztJgnaXBOkvDWnW+35GfarwImoiIiGSHAYiIiIhkhwFIYhqNBomJidBoNLaeykONdZYG6ywN1lkarLM0GkqdeRE0ERERyQ6PABEREZHsMAARERGR7DAAERERkewwABEREZHsMABZwZIlSxAQEAAHBweEhITg4MGD9+y/fv16BAYGwsHBAUFBQdi2bZtEM23c6lPn5cuXo1+/fmjWrBmaNWuG8PDw+/670F31fT9XS01NhUKhwNChQ607wYdEfet88+ZNTJkyBT4+PtBoNGjfvj3/21EH9a1zcnIyOnToAEdHR/j7+2PatGkoLy+XaLaN0/fff48hQ4bA19cXCoUCmzdvvu86WVlZ6N69OzQaDdq1a4fVq1dbfZ4QZFGpqanC3t5erFy5Uvz8889i/Pjxws3NTRQUFJjsv3fvXqFSqcR7770nTp48KWbPni3UarX46aefJJ5541LfOo8cOVIsWbJEHD16VJw6dUqMHTtWuLq6iitXrkg888alvnWulpOTI/z8/ES/fv3Es88+K81kG7H61rmiokL06NFDREVFiT179oicnByRlZUljh07JvHMG5f61nnt2rVCo9GItWvXipycHLF9+3bh4+Mjpk2bJvHMG5dt27aJN954Q2zatEkAEF999dU9+1+8eFE4OTmJ+Ph4cfLkSfHxxx8LlUol0tPTrTpPBiAL69Wrl5gyZYphWafTCV9fX5GUlGSy//Dhw8XTTz9t1BYSEiImTJhg1Xk2dvWt859VVVUJZ2dnsWbNGmtN8aFgTp2rqqpE7969xf/+7/+KmJgYBqA6qG+dly1bJtq0aSMqKyulmuJDob51njJlinjyySeN2uLj40WfPn2sOs+HSV0C0IwZM0SnTp2M2qKjo0VkZKQVZyYET4FZUGVlJQ4fPozw8HBDm1KpRHh4OLKzs02uk52dbdQfACIjI2vtT+bV+c/Kysqg1WrRvHlza02z0TO3zgsWLICnpydeeeUVKabZ6JlT5y1btiA0NBRTpkyBl5cXOnfujIULF0Kn00k17UbHnDr37t0bhw8fNpwmu3jxIrZt24aoqChJ5iwXtvoc5MNQLaioqAg6nQ5eXl5G7V5eXjh9+rTJdfLz8032z8/Pt9o8Gztz6vxn//jHP+Dr61vjl45+Z06d9+zZgxUrVuDYsWMSzPDhYE6dL168iF27dmHUqFHYtm0bzp8/j8mTJ0Or1SIxMVGKaTc65tR55MiRKCoqQt++fSGEQFVVFSZOnIhZs2ZJMWXZqO1zsKSkBHfu3IGjo6NVtssjQCQ777zzDlJTU/HVV1/BwcHB1tN5aNy6dQujR4/G8uXL4e7ubuvpPNT0ej08PT3x2WefITg4GNHR0XjjjTeQkpJi66k9VLKysrBw4UIsXboUR44cwaZNm7B161a8+eabtp4aWQCPAFmQu7s7VCoVCgoKjNoLCgrg7e1tch1vb+969Sfz6lzt/fffxzvvvIOdO3eiS5cu1pxmo1ffOl+4cAGXLl3CkCFDDG16vR4AYGdnhzNnzqBt27bWnXQjZM772cfHB2q1GiqVytD22GOPIT8/H5WVlbC3t7fqnBsjc+o8Z84cjB49GuPGjQMABAUFobS0FK+++ireeOMNKJU8hmAJtX0Ouri4WO3oD8AjQBZlb2+P4OBgZGZmGtr0ej0yMzMRGhpqcp3Q0FCj/gCQkZFRa38yr84A8N577+HNN99Eeno6evToIcVUG7X61jkwMBA//fQTjh07Zvj5y1/+ggEDBuDYsWPw9/eXcvqNhjnv5z59+uD8+fOGgAkAZ8+ehY+PD8NPLcypc1lZWY2QUx06BR+jaTE2+xy06iXWMpSamio0Go1YvXq1OHnypHj11VeFm5ubyM/PF0IIMXr0aDFz5kxD/7179wo7Ozvx/vvvi1OnTonExER+Db4O6lvnd955R9jb24sNGzaIvLw8w8+tW7dstQuNQn3r/Gf8Fljd1LfOubm5wtnZWcTFxYkzZ86Ib775Rnh6eoq33nrLVrvQKNS3zomJicLZ2Vl8+eWX4uLFi2LHjh2ibdu2Yvjw4bbahUbh1q1b4ujRo+Lo0aMCgFi0aJE4evSo+OWXX4QQQsycOVOMHj3a0L/6a/Cvv/66OHXqlFiyZAm/Bt9Yffzxx6Jly5bC3t5e9OrVS+zfv9/wWlhYmIiJiTHqv27dOtG+fXthb28vOnXqJLZu3SrxjBun+tS5VatWAkCNn8TEROkn3sjU9/38RwxAdVffOu/bt0+EhIQIjUYj2rRpI95++21RVVUl8awbn/rUWavVinnz5om2bdsKBwcH4e/vLyZPnix+++036SfeiHz33Xcm/3tbXduYmBgRFhZWY51u3boJe3t70aZNG7Fq1Sqrz1MhBI/jERERkbzwGiAiIiKSHQYgIiIikh0GICIiIpIdBiAiIiKSHQYgIiIikh0GICIiIpIdBiAiIiKSHQYgIqI6UigU2Lx5MwDg0qVLUCgUOHbsmE3nRETmYQAiokZh7NixUCgUUCgUUKvVaN26NWbMmIHy8nJbT42IGiE+DZ6IGo1BgwZh1apV0Gq1OHz4MGJiYqBQKPDuu+/aempE1MjwCBARNRoajQbe3t7w9/fH0KFDER4ejoyMDAB3n+ydlJSE1q1bw9HREV27dsWGDRuM1v/555/xzDPPwMXFBc7OzujXrx8uXLgAADh06BAGDhwId3d3uLq6IiwsDEeOHJF8H4lIGgxARNQonThxAvv27YO9vT0AICkpCf/617+QkpKCn3/+GdOmTcNLL72E3bt3AwCuXr2KJ554AhqNBrt27cLhw4fx8ssvo6qqCgBw69YtxMTEYM+ePdi/fz8effRRREVF4datWzbbRyKyHp4CI6JG45tvvkHTpk1RVVWFiooKKJVKfPLJJ6ioqMDChQuxc+dOhIaGAgDatGmDPXv24NNPP0VYWBiWLFkCV1dXpKamQq1WAwDat29vGPvJJ5802tZnn30GNzc37N69G88884x0O0lEkmAAIqJGY8CAAVi2bBlKS0vx4Ycfws7ODn/961/x888/o6ysDAMHDjTqX1lZiccffxwAcOzYMfTr188Qfv6soKAAs2fPRlZWFq5fvw6dToeysjLk5uZafb+ISHoMQETUaDRp0gTt2rUDAKxcuRJdu3bFihUr0LlzZwDA1q1b4efnZ7SORqMBADg6Ot5z7JiYGNy4cQOLFy9Gq1atoNFoEBoaisrKSivsCRHZGgMQETVKSqUSs2bNQnx8PM6ePQuNRoPc3FyEhYWZ7N+lSxesWbMGWq3W5FGgvXv3YunSpYiKigIAXL58GUVFRVbdByKyHV4ETUSN1gsvvACVSoVPP/0U06dPx7Rp07BmzRpcuHABR44cwccff4w1a9YAAOLi4lBSUoIXX3wRP/74I86dO4fPP/8cZ86cAQA8+uij+Pzzz3Hq1CkcOHAAo0aNuu9RIyJqvHgEiIgaLTs7O8TFxeG9995DTk4OPDw8kJSUhIsXL8LNzQ3du3fHrFmzAACPPPIIdu3ahddffx1hYWFQqVTo1q0b+vTpAwBYsWIFXn31VXTv3h3+/v5YuHAhpk+fbsvdIyIrUgghhK0nQURERCQlngIjIiIi2WEAIiIiItlhACIiIiLZYQAiIiIi2WEAIiIiItlhACIiIiLZYQAiIiIi2WEAIiIiItlhACIiIiLZYQAiIiIi2WEAIiIiItlhACIiIiLZ+X/84tRhCc7rWAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#44.  Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define base learners\n",
        "base_learners = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "]\n",
        "\n",
        "# Meta learner\n",
        "meta_learner = LogisticRegression()\n",
        "\n",
        "# Stacking Classifier\n",
        "stacking_clf = StackingClassifier(estimators=base_learners, final_estimator=meta_learner, cv=5)\n",
        "stacking_clf.fit(X_train, y_train)\n",
        "\n",
        "# Prediction and accuracy\n",
        "y_pred = stacking_clf.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Stacking Classifier Accuracy:\", acc)\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkBhaPdxq55_",
        "outputId": "78c2dfe3-6074-4a33-e7eb-b6b852f001b5"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Accuracy: 0.9649122807017544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#45.Train a Bagging Regressor with different levels of bootstrap samples and compare performance.\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load dataset\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Try different bootstrap sample fractions\n",
        "sample_fractions = [0.4, 0.6, 0.8, 1.0]\n",
        "\n",
        "for frac in sample_fractions:\n",
        "    model = BaggingRegressor(\n",
        "        estimator=DecisionTreeRegressor(), # Changed from base_estimator\n",
        "        n_estimators=50,\n",
        "        max_samples=frac,\n",
        "        random_state=42\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f\"Bootstrap Sample Fraction {frac}: MSE = {mse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEpCWU6hq51L",
        "outputId": "f8a1ca68-d4fa-4ca7-dfe2-5aac4201c532"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrap Sample Fraction 0.4: MSE = 0.2718\n",
            "Bootstrap Sample Fraction 0.6: MSE = 0.2644\n",
            "Bootstrap Sample Fraction 0.8: MSE = 0.2643\n",
            "Bootstrap Sample Fraction 1.0: MSE = 0.2573\n"
          ]
        }
      ]
    }
  ]
}